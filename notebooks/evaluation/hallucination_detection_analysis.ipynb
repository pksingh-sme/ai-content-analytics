{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d3139bc",
   "metadata": {},
   "source": [
    "# Advanced Hallucination Detection and Evaluation\n",
    "\n",
    "This notebook focuses on advanced hallucination detection techniques and comprehensive evaluation methodologies for LLM responses in RAG systems.\n",
    "\n",
    "## Key Features Covered:\n",
    "- Advanced hallucination detection algorithms\n",
    "- Factuality assessment\n",
    "- Contradiction analysis\n",
    "- Confidence scoring\n",
    "- Real-world scenario testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5218bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add backend to path\n",
    "sys.path.append('../../backend')\n",
    "\n",
    "# Import evaluation services\n",
    "from evaluation.evaluation_service import evaluation_service\n",
    "\n",
    "# Plotting configuration\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"Set2\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477d9e40",
   "metadata": {},
   "source": [
    "## Test Dataset Creation\n",
    "\n",
    "Create diverse test scenarios to evaluate hallucination detection capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b43494e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth documents with known facts\n",
    "ground_truth_documents = [\n",
    "    {\n",
    "        \"id\": \"gt_1\",\n",
    "        \"title\": \"Historical Facts: World War II\",\n",
    "        \"content\": \"\"\"World War II lasted from 1939 to 1945. \n",
    "        The war involved most of the world's nations forming two opposing military alliances: the Allies and the Axis. \n",
    "        Key events include the invasion of Poland in 1939, Pearl Harbor attack in 1941, and D-Day landings in 1944. \n",
    "        The war ended with the surrender of Germany in May 1945 and Japan in August 1945. \n",
    "        Total casualties were estimated at 70-85 million people.\"\"\",\n",
    "        \"facts\": [\n",
    "            \"WWII lasted from 1939 to 1945\",\n",
    "            \"Allies vs Axis powers\",\n",
    "            \"Invasion of Poland in 1939\",\n",
    "            \"Pearl Harbor attack in 1941\",\n",
    "            \"D-Day landings in 1944\",\n",
    "            \"Germany surrendered in May 1945\",\n",
    "            \"Japan surrendered in August 1945\",\n",
    "            \"70-85 million casualties\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"gt_2\",\n",
    "        \"title\": \"Scientific Facts: Climate Science\",\n",
    "        \"content\": \"\"\"Human activities have caused approximately 1.1¬∞C of global warming above pre-industrial levels. \n",
    "        Carbon dioxide concentrations have increased from 280 parts per million to over 420 ppm. \n",
    "        The last decade (2011-2020) was the warmest on record. \n",
    "        Arctic sea ice extent has declined by about 13% per decade. \n",
    "        Sea levels are rising at 3.3 mm per year due to thermal expansion and ice sheet melt.\"\"\",\n",
    "        \"facts\": [\n",
    "            \"1.1¬∞C global warming above pre-industrial levels\",\n",
    "            \"CO2 from 280 to 420+ ppm\",\n",
    "            \"2011-2020 warmest decade on record\",\n",
    "            \"Arctic sea ice decline 13% per decade\",\n",
    "            \"Sea level rise 3.3 mm/year\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"gt_3\",\n",
    "        \"title\": \"Technology Facts: Computing History\",\n",
    "        \"content\": \"\"\"The first electronic computer ENIAC was built in 1946 at the University of Pennsylvania. \n",
    "        Moore's Law predicted transistor density would double every two years. \n",
    "        The internet originated from ARPANET project in 1969. \n",
    "        First personal computer Altair 8800 was released in 1975. \n",
    "        World Wide Web was invented by Tim Berners-Lee in 1989.\"\"\",\n",
    "        \"facts\": [\n",
    "            \"ENIAC built in 1946\",\n",
    "            \"Moore's Law: doubling every 2 years\",\n",
    "            \"ARPANET project started in 1969\",\n",
    "            \"Altair 8800 released in 1975\",\n",
    "            \"WWW invented by Tim Berners-Lee in 1989\"\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Test scenarios with varying hallucination likelihood\n",
    "test_scenarios = [\n",
    "    {\n",
    "        \"name\": \"Accurate Response\",\n",
    "        \"query\": \"When did World War II end and what were the key events leading to its conclusion?\",\n",
    "        \"ground_truth_doc\": ground_truth_documents[0],\n",
    "        \"expected_response\": \"\"\"World War II ended in 1945 with Germany surrendering in May and Japan surrendering in August. \n",
    "        Key events included the D-Day landings in 1944, the Battle of the Bulge, \n",
    "        and the atomic bombings of Hiroshima and Nagasaki.\"\"\",\n",
    "        \"hallucination_level\": \"none\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Partial Hallucination\",\n",
    "        \"query\": \"What caused global warming and what are the current CO2 levels?\",\n",
    "        \"ground_truth_doc\": ground_truth_documents[1],\n",
    "        \"expected_response\": \"\"\"Human activities have caused approximately 1.1¬∞C of global warming. \n",
    "        Current carbon dioxide concentrations are over 420 parts per million. \n",
    "        However, some scientists believe solar activity is the primary cause of recent warming.\n",
    "        The Paris Agreement aims to limit warming to 1.5¬∞C above pre-industrial levels.\"\"\",\n",
    "        \"hallucination_level\": \"moderate\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Significant Hallucination\",\n",
    "        \"query\": \"Tell me about early computer history and internet development.\",\n",
    "        \"ground_truth_doc\": ground_truth_documents[2],\n",
    "        \"expected_response\": \"\"\"The first computer was built in 1846 by Charles Babbage. \n",
    "        The internet was invented by Al Gore in 1995. \n",
    "        Windows 95 was the first operating system released in 1981. \n",
    "        Steve Jobs created the first smartphone in 1990.\n",
    "        Social media platforms existed in the 1970s.\"\"\",\n",
    "        \"hallucination_level\": \"high\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Factual but Unsupported Claims\",\n",
    "        \"query\": \"What are the impacts of climate change on polar regions?\",\n",
    "        \"ground_truth_doc\": ground_truth_documents[1],\n",
    "        \"expected_response\": \"\"\"Arctic sea ice has declined by 13% per decade. \n",
    "        Polar bears are facing extinction due to habitat loss. \n",
    "        Antarctic ice sheets are melting at unprecedented rates. \n",
    "        Permafrost is thawing and releasing methane gas. \n",
    "        Ocean acidification is affecting marine ecosystems globally.\n",
    "        The North Pole will be ice-free by 2030 according to recent studies.\"\"\",\n",
    "        \"hallucination_level\": \"unsupported\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Mixed Accuracy\",\n",
    "        \"query\": \"How has technology evolved from early computers to modern AI?\",\n",
    "        \"ground_truth_doc\": ground_truth_documents[2],\n",
    "        \"expected_response\": \"\"\"ENIAC was built in 1946 at University of Pennsylvania. \n",
    "        The internet originated from ARPANET in 1969. \n",
    "        Artificial intelligence breakthroughs occurred in the 2010s with deep learning. \n",
    "        Quantum computers will revolutionize computing by 2030. \n",
    "        Brain-computer interfaces are already widely available in consumer markets.\n",
    "        Self-driving cars achieved full autonomy in 2018.\"\"\",\n",
    "        \"hallucination_level\": \"mixed\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"Created {len(ground_truth_documents)} ground truth documents\")\n",
    "print(f\"Created {len(test_scenarios)} test scenarios with varying hallucination levels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e89d7ef",
   "metadata": {},
   "source": [
    "## Hallucination Detection Analysis\n",
    "\n",
    "Run comprehensive hallucination detection on test scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5394e0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def analyze_hallucination_detection(scenarios):\n",
    "    \"\"\"Analyze hallucination detection across different scenarios\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for i, scenario in enumerate(scenarios):\n",
    "        print(f\"\\nAnalyzing Scenario {i+1}: {scenario['name']}\")\n",
    "        print(f\"Query: {scenario['query'][:60]}...\")\n",
    "        print(f\"Expected Hallucination Level: {scenario['hallucination_level']}\")\n",
    "        \n",
    "        # Get ground truth document\n",
    "        gt_doc = scenario['ground_truth_doc']\n",
    "        retrieved_docs = [gt_doc]\n",
    "        \n",
    "        # Analyze the response\n",
    "        response = scenario['expected_response']\n",
    "        hallucination_metrics = await evaluation_service.detect_hallucination(\n",
    "            response=response,\n",
    "            retrieved_docs=retrieved_docs,\n",
    "            query=scenario['query']\n",
    "        )\n",
    "        \n",
    "        # Log evaluation\n",
    "        log_id = await evaluation_service.log_evaluation_metrics(\n",
    "            query=scenario['query'],\n",
    "            response=response,\n",
    "            retrieved_docs=retrieved_docs,\n",
    "            rag_metrics={},  # Not evaluating RAG for this test\n",
    "            hallucination_metrics=hallucination_metrics,\n",
    "            additional_metadata={\n",
    "                \"test_type\": \"hallucination_detection\",\n",
    "                \"scenario_name\": scenario['name'],\n",
    "                \"expected_level\": scenario['hallucination_level']\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        result = {\n",
    "            \"scenario_name\": scenario['name'],\n",
    "            \"hallucination_level\": scenario['hallucination_level'],\n",
    "            \"hallucination_score\": hallucination_metrics['hallucination_score'],\n",
    "            \"factuality_score\": hallucination_metrics['factuality_score'],\n",
    "            \"confidence\": hallucination_metrics['confidence'],\n",
    "            \"contradiction_score\": hallucination_metrics['contradiction_score'],\n",
    "            \"supported_sentences\": hallucination_metrics['supported_sentences'],\n",
    "            \"total_sentences\": hallucination_metrics['total_sentences'],\n",
    "            \"alerts\": hallucination_metrics['alerts'],\n",
    "            \"fact_claims_count\": hallucination_metrics['analysis_details']['fact_claims_count'],\n",
    "            \"support_ratio\": hallucination_metrics['analysis_details']['support_ratio'],\n",
    "            \"log_id\": log_id\n",
    "        }\n",
    "        \n",
    "        results.append(result)\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"  Hallucination Score: {result['hallucination_score']:.3f}\")\n",
    "        print(f\"  Factuality Score: {result['factuality_score']:.3f}\")\n",
    "        print(f\"  Confidence: {result['confidence']:.3f}\")\n",
    "        print(f\"  Supported Sentences: {result['supported_sentences']}/{result['total_sentences']}\")\n",
    "        if result['alerts']:\n",
    "            print(f\"  Alerts: {result['alerts']}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run hallucination analysis\n",
    "hallucination_results = await analyze_hallucination_detection(test_scenarios)\n",
    "print(f\"\\nCompleted hallucination analysis for {len(hallucination_results)} scenarios\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b279251",
   "metadata": {},
   "source": [
    "## Hallucination Detection Visualization\n",
    "\n",
    "Visualize hallucination detection performance and effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7413aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to DataFrame\n",
    "df_hallucination = pd.DataFrame(hallucination_results)\n",
    "\n",
    "print(\"Hallucination Detection Results:\")\n",
    "display(df_hallucination.round(3))\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Hallucination Detection Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Hallucination scores by scenario\n",
    "bars = axes[0, 0].bar(range(len(df_hallucination)), df_hallucination['hallucination_score'], \n",
    "                     color=['green', 'yellow', 'red', 'orange', 'purple'])\n",
    "axes[0, 0].set_xlabel('Scenario')\n",
    "axes[0, 0].set_ylabel('Hallucination Score')\n",
    "axes[0, 0].set_title('Hallucination Scores by Scenario')\n",
    "axes[0, 0].set_xticks(range(len(df_hallucination)))\n",
    "axes[0, 0].set_xticklabels([f\"{name}\\n({level})\" for name, level in \n",
    "                           zip(df_hallucination['scenario_name'], df_hallucination['hallucination_level'])], \n",
    "                          rotation=45, ha='right')\n",
    "axes[0, 0].set_ylim(0, 1)\n",
    "for i, (bar, score) in enumerate(zip(bars, df_hallucination['hallucination_score'])):\n",
    "    axes[0, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
    "                   f'{score:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# 2. Factuality vs Confidence scatter\n",
    "scatter_colors = {'none': 'green', 'moderate': 'yellow', 'high': 'red', \n",
    "                  'unsupported': 'orange', 'mixed': 'purple'}\n",
    "for level in df_hallucination['hallucination_level'].unique():\n",
    "    mask = df_hallucination['hallucination_level'] == level\n",
    "    axes[0, 1].scatter(df_hallucination[mask]['factuality_score'], \n",
    "                      df_hallucination[mask]['confidence'],\n",
    "                      c=scatter_colors[level], label=level, s=100, alpha=0.7)\n",
    "axes[0, 1].set_xlabel('Factuality Score')\n",
    "axes[0, 1].set_ylabel('Confidence')\n",
    "axes[0, 1].set_title('Factuality vs Confidence by Hallucination Level')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].plot([0, 1], [1, 0], 'r--', alpha=0.5, label='Ideal Trade-off')\n",
    "\n",
    "# 3. Support ratio analysis\n",
    "support_ratios = [int(ratio.split('/')[0]) / int(ratio.split('/')[1]) \n",
    "                  for ratio in df_hallucination['support_ratio']]\n",
    "axes[0, 2].bar(range(len(support_ratios)), support_ratios, \n",
    "               color=['green', 'yellow', 'red', 'orange', 'purple'])\n",
    "axes[0, 2].set_xlabel('Scenario')\n",
    "axes[0, 2].set_ylabel('Support Ratio')\n",
    "axes[0, 2].set_title('Sentence Support Ratio')\n",
    "axes[0, 2].set_xticks(range(len(support_ratios)))\n",
    "axes[0, 2].set_xticklabels([name[:10] for name in df_hallucination['scenario_name']], \n",
    "                          rotation=45, ha='right')\n",
    "axes[0, 2].set_ylim(0, 1)\n",
    "\n",
    "# 4. Alert frequency by scenario\n",
    "alert_counts = [len(alerts) for alerts in df_hallucination['alerts']]\n",
    "axes[1, 0].bar(range(len(alert_counts)), alert_counts, \n",
    "               color=['green', 'yellow', 'red', 'orange', 'purple'])\n",
    "axes[1, 0].set_xlabel('Scenario')\n",
    "axes[1, 0].set_ylabel('Number of Alerts')\n",
    "axes[1, 0].set_title('Alert Generation by Scenario')\n",
    "axes[1, 0].set_xticks(range(len(alert_counts)))\n",
    "axes[1, 0].set_xticklabels([name[:10] for name in df_hallucination['scenario_name']], \n",
    "                          rotation=45, ha='right')\n",
    "\n",
    "# 5. Correlation heatmap\n",
    "correlation_features = ['hallucination_score', 'factuality_score', 'confidence', \n",
    "                       'contradiction_score', 'fact_claims_count']\n",
    "corr_matrix = df_hallucination[correlation_features].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, ax=axes[1, 1], cbar_kws={'shrink': 0.8})\n",
    "axes[1, 1].set_title('Feature Correlations')\n",
    "\n",
    "# 6. Performance radar chart\n",
    "from math import pi\n",
    "categories = ['Hallucination\\nScore', 'Factuality\\nScore', 'Confidence', \n",
    "              'Support\\nRatio', 'Contradiction\\nScore']\n",
    "\n",
    "# Prepare data for radar chart\n",
    "radar_data = []\n",
    "for _, row in df_hallucination.iterrows():\n",
    "    support_ratio_val = int(row['support_ratio'].split('/')[0]) / int(row['support_ratio'].split('/')[1])\n",
    "    data_point = [\n",
    "        1 - row['hallucination_score'],  # Invert for better visualization\n",
    "        row['factuality_score'],\n",
    "        row['confidence'],\n",
    "        support_ratio_val,\n",
    "        1 - row['contradiction_score']  # Invert contradiction score\n",
    "    ]\n",
    "    radar_data.append(data_point)\n",
    "\n",
    "# Radar chart\n",
    "angles = [n / float(len(categories)) * 2 * pi for n in range(len(categories))]\n",
    "angles += angles[:1]  # Close the circle\n",
    "\n",
    "ax_radar = plt.subplot(2, 3, 6, projection='polar')\n",
    "colors_radar = ['green', 'yellow', 'red', 'orange', 'purple']\n",
    "\n",
    "for i, (data, color, name) in enumerate(zip(radar_data, colors_radar, df_hallucination['scenario_name'])):\n",
    "    data += data[:1]  # Close the circle\n",
    "    ax_radar.plot(angles, data, 'o-', linewidth=2, label=name[:10], color=color)\n",
    "    ax_radar.fill(angles, data, alpha=0.25, color=color)\n",
    "\n",
    "ax_radar.set_xticks(angles[:-1])\n",
    "ax_radar.set_xticklabels(categories)\n",
    "ax_radar.set_ylim(0, 1)\n",
    "ax_radar.set_title('Performance Radar Chart', pad=20)\n",
    "ax_radar.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd90524c",
   "metadata": {},
   "source": [
    "## Detection Effectiveness Analysis\n",
    "\n",
    "Analyze how well the hallucination detection system identifies different types of hallucinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c234639",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Hallucination Detection Effectiveness Analysis ===\\n\")\n",
    "\n",
    "# Group results by expected hallucination level\n",
    "grouped_analysis = df_hallucination.groupby('hallucination_level').agg({\n",
    "    'hallucination_score': ['mean', 'std', 'min', 'max'],\n",
    "    'factuality_score': 'mean',\n",
    "    'confidence': 'mean',\n",
    "    'alerts': 'count'\n",
    "}).round(3)\n",
    "\n",
    "print(\"Performance by Expected Hallucination Level:\")\n",
    "display(grouped_analysis)\n",
    "\n",
    "# Detection accuracy analysis\n",
    "print(\"\\nDetection Accuracy Analysis:\")\n",
    "threshold = 0.3  # Hallucination score threshold\n",
    "\n",
    "detection_results = []\n",
    "for _, row in df_hallucination.iterrows():\n",
    "    expected = row['hallucination_level']\n",
    "    detected = row['hallucination_score'] > threshold\n",
    "    \n",
    "    # Map expected levels to binary classification\n",
    "    expected_positive = expected in ['moderate', 'high', 'mixed', 'unsupported']\n",
    "    \n",
    "    detection_results.append({\n",
    "        'scenario': row['scenario_name'],\n",
    "        'expected': expected,\n",
    "        'expected_positive': expected_positive,\n",
    "        'detected_positive': detected,\n",
    "        'hallucination_score': row['hallucination_score'],\n",
    "        'correct': expected_positive == detected\n",
    "    })\n",
    "\n",
    "df_detection = pd.DataFrame(detection_results)\n",
    "\n",
    "# Calculate metrics\n",
    "true_positives = len(df_detection[(df_detection['expected_positive'] == True) & \n",
    "                                 (df_detection['detected_positive'] == True)])\n",
    "false_positives = len(df_detection[(df_detection['expected_positive'] == False) & \n",
    "                                  (df_detection['detected_positive'] == True)])\n",
    "true_negatives = len(df_detection[(df_detection['expected_positive'] == False) & \n",
    "                                 (df_detection['detected_positive'] == False)])\n",
    "false_negatives = len(df_detection[(df_detection['expected_positive'] == True) & \n",
    "                                  (df_detection['detected_positive'] == False)])\n",
    "\n",
    "total = len(df_detection)\n",
    "accuracy = (true_positives + true_negatives) / total if total > 0 else 0\n",
    "precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(f\"\\nBinary Classification Metrics (Threshold = {threshold}):\")\n",
    "print(f\"  Accuracy: {accuracy:.3f} ({true_positives + true_negatives}/{total})\")\n",
    "print(f\"  Precision: {precision:.3f} ({true_positives}/{true_positives + false_positives})\")\n",
    "print(f\"  Recall: {recall:.3f} ({true_positives}/{true_positives + false_negatives})\")\n",
    "print(f\"  F1-Score: {f1_score:.3f}\")\n",
    "\n",
    "print(\"\\nDetailed Detection Results:\")\n",
    "display_df = df_detection[['scenario', 'expected', 'hallucination_score', 'detected_positive', 'correct']].copy()\n",
    "display_df.columns = ['Scenario', 'Expected Level', 'Score', 'Detected', 'Correct']\n",
    "display(display_df.round(3))\n",
    "\n",
    "# Alert effectiveness\n",
    "print(\"\\nAlert Effectiveness Analysis:\")\n",
    "scenarios_with_alerts = df_hallucination[df_hallucination['alerts'].apply(len) > 0]\n",
    "if len(scenarios_with_alerts) > 0:\n",
    "    avg_hallucination_with_alerts = scenarios_with_alerts['hallucination_score'].mean()\n",
    "    avg_hallucination_without_alerts = df_hallucination[df_hallucination['alerts'].apply(len) == 0]['hallucination_score'].mean()\n",
    "    \n",
    "    print(f\"  Average hallucination score WITH alerts: {avg_hallucination_with_alerts:.3f}\")\n",
    "    print(f\"  Average hallucination score WITHOUT alerts: {avg_hallucination_without_alerts:.3f}\")\n",
    "    print(f\"  Alert discrimination power: {abs(avg_hallucination_with_alerts - avg_hallucination_without_alerts):.3f}\")\n",
    "else:\n",
    "    print(\"  No alerts generated in test scenarios\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22c2d59",
   "metadata": {},
   "source": [
    "## Advanced Analysis and Recommendations\n",
    "\n",
    "Provide detailed analysis and improvement recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dcbc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Advanced Analysis and Recommendations ===\\n\")\n",
    "\n",
    "# Performance insights\n",
    "avg_hallucination = df_hallucination['hallucination_score'].mean()\n",
    "avg_factuality = df_hallucination['factuality_score'].mean()\n",
    "avg_confidence = df_hallucination['confidence'].mean()\n",
    "total_alerts = sum(len(alerts) for alerts in df_hallucination['alerts'])\n",
    "\n",
    "print(\"System Performance Summary:\")\n",
    "print(f\"  Average Hallucination Score: {avg_hallucination:.3f}\")\n",
    "print(f\"  Average Factuality Score: {avg_factuality:.3f}\")\n",
    "print(f\"  Average Confidence: {avg_confidence:.3f}\")\n",
    "print(f\"  Total Alerts Generated: {total_alerts}\")\n",
    "print(f\"  Scenarios with Alerts: {len([a for a in df_hallucination['alerts'] if len(a) > 0])}/{len(df_hallucination)}\")\n",
    "\n",
    "# Identify strengths and weaknesses\n",
    "print(\"\\nPerformance Analysis:\")\n",
    "\n",
    "if avg_hallucination < 0.2:\n",
    "    print(\"‚úÖ Strength: Low average hallucination rate indicates good detection capability\")\n",
    "elif avg_hallucination < 0.4:\n",
    "    print(\"‚ö†Ô∏è Moderate: Hallucination detection working reasonably well\")\n",
    "else:\n",
    "    print(\"‚ùå Weakness: High hallucination rates suggest detection improvements needed\")\n",
    "\n",
    "if avg_factuality > 0.8:\n",
    "    print(\"‚úÖ Strength: High factuality scores indicate reliable information extraction\")\n",
    "elif avg_factuality > 0.6:\n",
    "    print(\"‚ö†Ô∏è Moderate: Factuality could be improved\")\n",
    "else:\n",
    "    print(\"‚ùå Weakness: Low factuality suggests issues with source document matching\")\n",
    "\n",
    "if avg_confidence > 0.8:\n",
    "    print(\"‚úÖ Strength: High confidence indicates consistent performance\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Note: Variable confidence may indicate inconsistent performance\")\n",
    "\n",
    "# Detailed scenario analysis\n",
    "print(\"\\nScenario-Specific Insights:\")\n",
    "for _, row in df_hallucination.iterrows():\n",
    "    level = row['hallucination_level']\n",
    "    score = row['hallucination_score']\n",
    "    \n",
    "    if level == 'none' and score > 0.1:\n",
    "        print(f\"‚ö†Ô∏è False Positive: {row['scenario_name']} (Score: {score:.3f}) - Detected hallucination in accurate response\")\n",
    "    elif level in ['high', 'moderate'] and score < 0.2:\n",
    "        print(f\"‚ö†Ô∏è False Negative: {row['scenario_name']} (Score: {score:.3f}) - Failed to detect clear hallucination\")\n",
    "    elif level == 'unsupported' and score < 0.3:\n",
    "        print(f\"üîç Nuanced Detection: {row['scenario_name']} (Score: {score:.3f}) - Correctly identified unsupported claims\")\n",
    "\n",
    "# Recommendations\n",
    "print(\"\\nRecommendations for Improvement:\")\n",
    "recommendations = []\n",
    "\n",
    "if avg_hallucination > 0.3:\n",
    "    recommendations.append(\"Implement more sophisticated semantic similarity measures for better document matching\")\n",
    "    recommendations.append(\"Add external fact-checking APIs for controversial claims\")\n",
    "    recommendations.append(\"Increase training data diversity for hallucination detection\")\n",
    "\n",
    "if total_alerts == 0:\n",
    "    recommendations.append(\"Review and adjust alert thresholds to catch more issues\")\n",
    "    recommendations.append(\"Consider adding more granular alert types\")\n",
    "elif total_alerts > len(df_hallucination) * 2:\n",
    "    recommendations.append(\"Review alert thresholds - may be generating too many false positives\")\n",
    "    recommendations.append(\"Implement alert prioritization system\")\n",
    "\n",
    "recommendations.extend([\n",
    "    \"Add human validation loop for high-confidence hallucination detections\",\n",
    "    \"Implement continuous learning from feedback to improve detection accuracy\",\n",
    "    \"Create detailed logging for false positive/negative analysis\",\n",
    "    \"Develop ensemble methods combining multiple detection approaches\",\n",
    "    \"Add temporal analysis to track hallucination trends over time\",\n",
    "    \"Implement user feedback mechanisms for hallucination reporting\"\n",
    "])\n",
    "\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    print(f\"{i}. {rec}\")\n",
    "\n",
    "# Threshold optimization suggestion\n",
    "print(\"\\nThreshold Optimization Suggestions:\")\n",
    "optimal_threshold = df_hallucination['hallucination_score'].median()\n",
    "print(f\"  Current median hallucination score: {optimal_threshold:.3f}\")\n",
    "print(f\"  Suggested threshold adjustment range: {max(0.1, optimal_threshold-0.1):.3f} - {min(0.9, optimal_threshold+0.1):.3f}\")\n",
    "print(\"  Recommendation: Test multiple thresholds and select based on precision-recall trade-off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889276eb",
   "metadata": {},
   "source": [
    "## Export Analysis Results\n",
    "\n",
    "Save detailed analysis results for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ed5de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Save detailed results\n",
    "results_filename = f\"hallucination_detection_results_{timestamp}.csv\"\n",
    "df_hallucination.to_csv(results_filename, index=False)\n",
    "print(f\"Detailed results saved to: {results_filename}\")\n",
    "\n",
    "# Save detection analysis\n",
    "detection_filename = f\"detection_analysis_{timestamp}.csv\"\n",
    "df_detection.to_csv(detection_filename, index=False)\n",
    "print(f\"Detection analysis saved to: {detection_filename}\")\n",
    "\n",
    "# Save comprehensive report\n",
    "report_filename = f\"hallucination_analysis_report_{timestamp}.txt\"\n",
    "with open(report_filename, 'w') as f:\n",
    "    f.write(\"HALLUCINATION DETECTION ANALYSIS REPORT\\n\")\n",
    "    f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "    f.write(f\"Generated: {datetime.now().isoformat()}\\n\")\n",
    "    f.write(f\"Test Scenarios: {len(test_scenarios)}\\n\\n\")\n",
    "    \n",
    "    f.write(\"OVERALL PERFORMANCE:\\n\")\n",
    "    f.write(f\"  Average Hallucination Score: {avg_hallucination:.3f}\\n\")\n",
    "    f.write(f\"  Average Factuality Score: {avg_factuality:.3f}\\n\")\n",
    "    f.write(f\"  Average Confidence: {avg_confidence:.3f}\\n\")\n",
    "    f.write(f\"  Detection Accuracy: {accuracy:.3f}\\n\")\n",
    "    f.write(f\"  Precision: {precision:.3f}\\n\")\n",
    "    f.write(f\"  Recall: {recall:.3f}\\n\\n\")\n",
    "    \n",
    "    f.write(\"DETECTION METRICS:\\n\")\n",
    "    f.write(f\"  True Positives: {true_positives}\\n\")\n",
    "    f.write(f\"  False Positives: {false_positives}\\n\")\n",
    "    f.write(f\"  True Negatives: {true_negatives}\\n\")\n",
    "    f.write(f\"  False Negatives: {false_negatives}\\n\\n\")\n",
    "    \n",
    "    f.write(\"RECOMMENDATIONS:\\n\")\n",
    "    for rec in recommendations:\n",
    "        f.write(f\"  ‚Ä¢ {rec}\\n\")\n",
    "\n",
    "print(f\"Comprehensive report saved to: {report_filename}\")\n",
    "print(\"\\n‚úÖ Hallucination detection analysis completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
